[config]
    "alg_name"          = "ppo"
    "env_name"          = "LunarLanderContinuous-v2"
    "render"            = true
    "solved_reward"     = 300  # stop training if avg_reward > solved_reward
    "log_interval"      = 1  # print avg reward in the interval
    "max_episodes"      = 100000 # max training episodes
    "max_timesteps"     = 1000  # max timesteps in one episode
    "update_timestep"   = 500  # update policy every n timesteps

    "action_std" = 0.5  # constant std for action distribution (Multivariate Normal)
    "K_epochs" = 80  # update policy for K epochs
    "eps_clip" = 0.2  # clip parameter for PPO
    "gamma" = 0.99  # discount factor
    "lr" = 0.0003  # parameters for Adam optimizer
    "betas" = [0.9, 0.999]

    "buffer_size"=512
    "device"="cpu"